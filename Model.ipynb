{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TazVdyDk0D_m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models, transforms, datasets\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #checking for gpu"
      ],
      "metadata": {
        "id": "rVWkV8ay0Ir1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ie_meTDJ0Kde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ece8f5-227e-49e3-b9dc-10f3824b2dfe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/capstone_ml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3DDXwa7xgB9",
        "outputId": "a97fa4bb-bdc6-4b72-c8da-c556f40b7190"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/capstone_ml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Dataset\n"
      ],
      "metadata": {
        "id": "T8-sO5MkwknC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining custom dataset to input to model\n",
        "class EarningsDataset(data.Dataset):\n",
        "  def __init__(self, csv_file, root_dir, transform=None):\n",
        "    self.annotations = pd.read_csv(csv_file)\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    name = str(self.annotations.iloc[index,0])\n",
        "    y_label = self.annotations.iloc[index,1]\n",
        "    example = torch.load(self.root_dir+name) #loading saved torch tensor representing file\n",
        "    time_series = example[\"time_series\"]\n",
        "    volatility = example[\"volatility\"] if not torch.isnan(example[\"volatility\"]).any() else torch.tensor(1)\n",
        "    volume = example[\"volume\"] if not torch.isnan(example[\"volume\"]).any() else torch.tensor(1)\n",
        "    marketcap = example[\"marketcap\"] if not torch.isnan(example[\"marketcap\"]).any() else torch.tensor(1)\n",
        "    sector = example[\"sector\"]\n",
        "    industry = example[\"industry\"]\n",
        "\n",
        "    return (time_series, volatility, volume, marketcap, sector, industry), y_label"
      ],
      "metadata": {
        "id": "56DGhvaX0NqL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating Train Test Split"
      ],
      "metadata": {
        "id": "SSWpe6uswsw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = EarningsDataset(csv_file=\"annotations3.csv\", root_dir=\"training_data3/\")\n",
        "total_size = len(dataset)\n",
        "print(len(dataset))\n",
        "train_size = int(0.8 * total_size)\n",
        "test_size = total_size - train_size\n",
        "\n",
        "train_dataset, test_dataset = data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "batch_size = 64\n",
        "trainloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
        "testloader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)"
      ],
      "metadata": {
        "id": "pp-eeW29uuv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28bf77b7-f40a-4aae-bc18-a6264d0e7d04"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RNN Model"
      ],
      "metadata": {
        "id": "NpkqCTBcw2rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(RNNModel, self).__init__()\n",
        "      self.lstm = nn.LSTM(input_size=6, hidden_size=20, num_layers=2, batch_first=True)\n",
        "      self.fc1 = nn.Linear(34, 16)\n",
        "      self.fc2 = nn.Linear(16, 1)\n",
        "      self.activation = nn.Tanh()\n",
        "\n",
        "  def forward(self, time_series, scalar):\n",
        "      h0 = torch.zeros(2, batch_size, 20).to(device)\n",
        "      c0 = torch.zeros(2, batch_size, 20).to(device)\n",
        "      output, (hn, cn) = self.lstm(time_series, (h0, c0))\n",
        "      embedding = hn[-1]\n",
        "      combined = torch.cat((embedding, scalar), dim=1)\n",
        "      combined = self.activation(self.fc1(combined))\n",
        "      output = self.fc2(combined)\n",
        "      output = self.activation(output)\n",
        "      return output"
      ],
      "metadata": {
        "id": "7EZG1H0b76Yf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN Model"
      ],
      "metadata": {
        "id": "lhcEVR_5w5sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(CNNModel, self).__init__()\n",
        "      self.conv1 = nn.Conv1d(in_channels=6, out_channels=10, kernel_size=2)\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.fc1 = nn.Linear(64, 16)\n",
        "      self.fc2 = nn.Linear(16, 1)\n",
        "      self.activation = nn.Tanh()\n",
        "\n",
        "  def forward(self, time_series, scalar):\n",
        "      embedding = self.conv1(time_series)\n",
        "      embedding = self.flatten(embedding)\n",
        "      combined = torch.cat((embedding, scalar), dim=1)\n",
        "      x = self.fc1(combined)\n",
        "      x = self.activation(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "JD66ZkIO1_us"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train, Test Loop"
      ],
      "metadata": {
        "id": "xEKxrHZ5w79m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNModel()\n",
        "model.to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(5):\n",
        "    train_loss = 0\n",
        "    for inputs, labels in trainloader:\n",
        "      labels = labels.to(device)\n",
        "      time_series, volatility, volume, marketcap, sector, industry = inputs\n",
        "      time_series = time_series.to(device)\n",
        "      scalar_inputs = torch.cat([volatility.unsqueeze(1).to(device), volume.unsqueeze(1).to(device), marketcap.unsqueeze(1), sector.to(device)], dim=1)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(time_series.float(), scalar_inputs.float())\n",
        "      loss = loss_function(outputs, labels.unsqueeze(1).float())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()*batch_size\n",
        "\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in testloader:\n",
        "        labels = labels.to(device)\n",
        "        time_series, volatility, volume, marketcap, sector, industry = inputs\n",
        "        time_series = time_series.to(device)\n",
        "        scalar_inputs = torch.cat([volatility.unsqueeze(1).to(device), volume.unsqueeze(1).to(device), marketcap.unsqueeze(1), sector.to(device)], dim=1)\n",
        "\n",
        "        outputs = model(time_series.float(), scalar_inputs.float())\n",
        "        loss = loss_function(outputs, labels.unsqueeze(1).float())\n",
        "        test_loss += loss.item()*batch_size\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_loss/len(trainloader.dataset)}, Test Loss:{test_loss/len(testloader.dataset)}')"
      ],
      "metadata": {
        "id": "XMfssviI-rO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f05a875-a997-430b-c4f1-d7cba96f4dd9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 0.16144619064287483, Test Loss:0.1070354420300488\n",
            "Epoch 2, Train Loss: 0.12772095319136834, Test Loss:0.10095937175837826\n",
            "Epoch 3, Train Loss: 0.1252231262943392, Test Loss:0.09729819428430844\n",
            "Epoch 4, Train Loss: 0.12422918769579352, Test Loss:0.09957278917913567\n",
            "Epoch 5, Train Loss: 0.1224068960824876, Test Loss:0.08923574343119582\n"
          ]
        }
      ]
    }
  ]
}